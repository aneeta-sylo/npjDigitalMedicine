{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Study: The Impact of Inconsistent Human Annotations on AI driven Clinical Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statistics\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import multilabel_confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score \n",
    "from statsmodels.stats.inter_rater import fleiss_kappa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to HiRID database\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "#Connect to HiRID\n",
    "conn = psycopg2.connect(user=\"mimicuser\",\n",
    "                                  password=\"knowlabMIMIC\",\n",
    "                                  host=\"172.17.0.1\",\n",
    "                                  port=\"5433\",\n",
    "                                  database=\"HiRID\")\n",
    "\n",
    "#Cursor \n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Training Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: All annotated datasets were provided by the data controller (Prof. Malcolm Sim) as excel files. In this section, all datasets are imported in their raw format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define funtion to add numeric label columns to all 11 QEUH annotated datasets\n",
    "\n",
    "def num_labels(df):\n",
    "\n",
    "    #Add numeric multiclass Annotation column\n",
    "    df['Annotation_Num'] = 0\n",
    "    df.loc[df['Annotation'] == 'A', 'Annotation_Num'] = 0\n",
    "    df.loc[df['Annotation'] == 'B', 'Annotation_Num'] = 1\n",
    "    df.loc[df['Annotation'] == 'C', 'Annotation_Num'] = 2\n",
    "    df.loc[df['Annotation'] == 'D', 'Annotation_Num'] = 3\n",
    "    df.loc[df['Annotation'] == 'E', 'Annotation_Num'] = 4\n",
    "\n",
    "    #Create binary class column: A=0, B/C/D/E = 1\n",
    "    df['Ann_Bin_A'] = 0\n",
    "    df.loc[df['Annotation'] == 'A', 'Ann_Bin_A'] = 0\n",
    "    df.loc[df['Annotation'] == 'B', 'Ann_Bin_A'] = 1\n",
    "    df.loc[df['Annotation'] == 'C', 'Ann_Bin_A'] = 1\n",
    "    df.loc[df['Annotation'] == 'D', 'Ann_Bin_A'] = 1\n",
    "    df.loc[df['Annotation'] == 'E', 'Ann_Bin_A'] = 1\n",
    "\n",
    "    #Create binary class column: A/B = 0, C/D/E = 1\n",
    "    df['Ann_Bin_B'] = 0\n",
    "    df.loc[df['Annotation'] == 'A', 'Ann_Bin_B'] = 0\n",
    "    df.loc[df['Annotation'] == 'B', 'Ann_Bin_B'] = 0\n",
    "    df.loc[df['Annotation'] == 'C', 'Ann_Bin_B'] = 1\n",
    "    df.loc[df['Annotation'] == 'D', 'Ann_Bin_B'] = 1\n",
    "    df.loc[df['Annotation'] == 'E', 'Ann_Bin_B'] = 1\n",
    "\n",
    "    #Create binary class column: A/B/C = 0, D/E = 1\n",
    "    df['Ann_Bin_C'] = 0\n",
    "    df.loc[df['Annotation'] == 'A', 'Ann_Bin_C'] = 0\n",
    "    df.loc[df['Annotation'] == 'B', 'Ann_Bin_C'] = 0\n",
    "    df.loc[df['Annotation'] == 'C', 'Ann_Bin_C'] = 0\n",
    "    df.loc[df['Annotation'] == 'D', 'Ann_Bin_C'] = 1\n",
    "    df.loc[df['Annotation'] == 'E', 'Ann_Bin_C'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.1 dataset\n",
    "\n",
    "c1 = pd.read_excel('./p01.xlsx').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c1 = c1.drop(columns = cols)\n",
    "c1 = c1.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c1['Adrenaline'] = c1['Adrenaline'].replace(np.nan, 0)\n",
    "c1['Noradrenaline'] = c1['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c1 = num_labels(c1)\n",
    "\n",
    "print(c1.shape)\n",
    "c1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.2 dataset\n",
    "\n",
    "c2 = pd.read_csv('./p02.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c2 = c2.drop(columns = cols)\n",
    "c2 = c2.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c2['Adrenaline'] = c2['Adrenaline'].replace(np.nan, 0)\n",
    "c2['Noradrenaline'] = c2['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c2 = num_labels(c2)\n",
    "\n",
    "print(c2.shape)\n",
    "c2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.3 dataset\n",
    "\n",
    "c3 = pd.read_csv('./p03.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c3 = c3.drop(columns = cols)\n",
    "c3 = c3.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c3['Adrenaline'] = c3['Adrenaline'].replace(np.nan, 0)\n",
    "c3['Noradrenaline'] = c3['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c3 = num_labels(c3)\n",
    "\n",
    "print(c3.shape)\n",
    "c3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.4 dataset\n",
    "\n",
    "c4 = pd.read_excel('./p04.xlsx').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c4 = c4.drop(columns = cols)\n",
    "c4 = c4.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c4['Adrenaline'] = c4['Adrenaline'].replace(np.nan, 0)\n",
    "c4['Noradrenaline'] = c4['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c4 = num_labels(c4)\n",
    "\n",
    "print(c4.shape)\n",
    "c4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.5 dataset\n",
    "\n",
    "c5 = pd.read_csv('./p05.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c5 = c5.drop(columns = cols)\n",
    "c5 = c5.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c5['Adrenaline'] = c5['Adrenaline'].replace(np.nan, 0)\n",
    "c5['Noradrenaline'] = c5['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c5 = num_labels(c5)\n",
    "\n",
    "print(c5.shape)\n",
    "c5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.6 dataset\n",
    "\n",
    "c6 = pd.read_excel('./p06.xlsx').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c6 = c6.drop(columns = cols)\n",
    "c6 = c6.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c6['Adrenaline'] = c6['Adrenaline'].replace(np.nan, 0)\n",
    "c6['Noradrenaline'] = c6['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c6 = num_labels(c6)\n",
    "\n",
    "print(c6.shape)\n",
    "c6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.7 dataset\n",
    "\n",
    "c7 = pd.read_csv('./p07.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c7 = c7.drop(columns = cols)\n",
    "c7 = c7.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c7['Adrenaline'] = c7['Adrenaline'].replace(np.nan, 0)\n",
    "c7['Noradrenaline'] = c7['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c7 = num_labels(c7)\n",
    "\n",
    "print(c7.shape)\n",
    "c7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.8 dataset\n",
    "\n",
    "c8 = pd.read_csv('./p08.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c8 = c8.drop(columns = cols)\n",
    "c8 = c8.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c8['Adrenaline'] = c8['Adrenaline'].replace(np.nan, 0)\n",
    "c8['Noradrenaline'] = c8['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c8 = num_labels(c8)\n",
    "\n",
    "print(c8.shape)\n",
    "c8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.9 dataset\n",
    "\n",
    "c9 = pd.read_csv('./p09.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c9 = c9.drop(columns = cols)\n",
    "c9 = c9.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c9['Adrenaline'] = c9['Adrenaline'].replace(np.nan, 0)\n",
    "c9['Noradrenaline'] = c9['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c9 = num_labels(c9)\n",
    "\n",
    "print(c9.shape)\n",
    "c9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.10 dataset\n",
    "\n",
    "c10 = pd.read_csv('./p10.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c10 = c10.drop(columns = cols)\n",
    "c10 = c10.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c10['Adrenaline'] = c10['Adrenaline'].replace(np.nan, 0)\n",
    "c10['Noradrenaline'] = c10['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c10 = num_labels(c10)\n",
    "\n",
    "print(c10.shape)\n",
    "c10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Consultant no.11 dataset\n",
    "\n",
    "c11 = pd.read_excel('./p11.xlsx').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c11 = c11.drop(columns = cols)\n",
    "c11 = c11.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "c11['Adrenaline'] = c11['Adrenaline'].replace(np.nan, 0)\n",
    "c11['Noradrenaline'] = c11['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "c11['Annotation'] = c11['Annotation'].str.upper()\n",
    "\n",
    "c11 = num_labels(c11)\n",
    "\n",
    "print(c11.shape)\n",
    "c11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Majority MV Consensus Dataset\n",
    "##See jupyter notebook 'npjDM-MV_Consensus_Dataset' for steps to create this Majority MV Consensus Dataset\n",
    "\n",
    "mv = pd.read_csv('MV-Consensus-Dataset.csv')\n",
    "\n",
    "mv = mv.drop('Unnamed: 0',axis=1)\n",
    "mv = mv.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "mv['Adrenaline'] = mv['Adrenaline'].replace(np.nan, 0)\n",
    "mv['Noradrenaline'] = mv['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "mv = num_labels(mv)\n",
    "\n",
    "print(mv.shape)\n",
    "mv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMV\n",
    "##Create a TMV dataset by taking the majority-vote labels across only the expert annotated datasets which generate models that have high internal validation performance (i.e., where internal F1 >= 0.7).\n",
    "##See jupyter notebook 'npjDM-IntVal-Top_Models' for steps to find top performing models\n",
    "##Top performaing models within internal validation: C2, C4, C8\n",
    "\n",
    "c2_ann = pd.read_csv('./p02.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c2_ann = c2_ann.drop(columns = cols)\n",
    "c2_ann = c2_ann.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "c4_ann = pd.read_excel('./p04.xlsx').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c4_ann = c4_ann.drop(columns = cols)\n",
    "c4_ann = c4_ann.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "c8_ann = pd.read_csv('./p08.csv').sort_values(by = ['PseudoID'], ascending=[True])\n",
    "cols = ['Dobutamine','Time','Bckgrnd','PseudoID','Line of Selected Timepoint']\n",
    "c8_ann = c8_ann.drop(columns = cols)\n",
    "c8_ann = c8_ann.rename(columns={'Mean': 'MAP'}) #rename Mean to MAP\n",
    "\n",
    "cols = ['Adrenaline','Noradrenaline','FiO2','SpO2','MAP','HR']\n",
    "ann_top = c2_ann.merge(c4_ann,on=cols).merge(c8_ann,on=cols)\n",
    "\n",
    "ann_top.columns = ['Adrenaline','Noradrenaline','FiO2','SpO2','MAP','HR', 'c2_ann', 'c4_ann', 'c8_ann']\n",
    "\n",
    "colsb = ['Adrenaline', 'Noradrenaline','FiO2','SpO2','MAP','HR']\n",
    "ann_top.drop(colsb,axis=1,inplace=True)\n",
    "\n",
    "ann_top['Annotation']= ann_top.mode(axis=1)[0]\n",
    "colsc = ['c2_ann', 'c4_ann','c8_ann']\n",
    "ann_top.drop(colsc,axis=1,inplace=True)\n",
    "\n",
    "colsd = ['Adrenaline','Noradrenaline','FiO2','SpO2','MAP','HR']\n",
    "tmv = c2_ann.merge(c4_ann,on=colsd).merge(c8_ann,on=colsd)\n",
    "tmv.columns = ['Adrenaline','Noradrenaline','FiO2','SpO2','MAP','HR', 'c2_ann', 'c4_ann', 'c8_ann']\n",
    "\n",
    "tmv = pd.concat([tmv,ann_top],axis=1)\n",
    "colse = ['c2_ann', 'c4_ann','c8_ann']\n",
    "tmv.drop(colse,axis=1,inplace=True)\n",
    "\n",
    "#Replace null with 0 in drug fields (as blank value indicates value=0, as confirmed by Prof Sim)\n",
    "tmv['Adrenaline'] = tmv['Adrenaline'].replace(np.nan, 0)\n",
    "tmv['Noradrenaline'] = tmv['Noradrenaline'].replace(np.nan, 0)\n",
    "\n",
    "tmv = num_labels(tmv)\n",
    "\n",
    "print(tmv.shape)\n",
    "tmv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Investigate Inter-Annotator Agreement (IAA) - Cohen's kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with compiled annotation labels across all 11 consultant annotators\n",
    "\n",
    "c1sub = c1.iloc[:,:7]\n",
    "c1sub = c1sub.rename(columns={'Annotation': 'C1'})\n",
    "                            \n",
    "c2sub = c2.iloc[:,:7]\n",
    "c2sub = c2sub.rename(columns={'Annotation': 'C2'})\n",
    "\n",
    "c3sub = c3.iloc[:,:7]\n",
    "c3sub = c3sub.rename(columns={'Annotation': 'C3'})\n",
    "\n",
    "c4sub = c4.iloc[:,:7]\n",
    "c4sub = c4sub.rename(columns={'Annotation': 'C4'})\n",
    "\n",
    "c5sub = c5.iloc[:,:7]\n",
    "c5sub = c5sub.rename(columns={'Annotation': 'C5'})\n",
    "\n",
    "c6sub = c6.iloc[:,:7]\n",
    "c6sub = c6sub.rename(columns={'Annotation': 'C6'})\n",
    "\n",
    "c7sub = c7.iloc[:,:7]\n",
    "c7sub = c7sub.rename(columns={'Annotation': 'C7'})\n",
    "\n",
    "c8sub = c8.iloc[:,:7]\n",
    "c8sub = c8sub.rename(columns={'Annotation': 'C8'})\n",
    "\n",
    "c9sub = c9.iloc[:,:7]\n",
    "c9sub = c9sub.rename(columns={'Annotation': 'C9'})\n",
    "\n",
    "c10sub = c10.iloc[:,:7]\n",
    "c10sub = c10sub.rename(columns={'Annotation': 'C10'})\n",
    "\n",
    "c11sub = c11.iloc[:,:7]\n",
    "c11sub = c11sub.rename(columns={'Annotation': 'C11'})\n",
    "\n",
    "cols = ['Adrenaline','Noradrenaline','FiO2','SpO2','MAP','HR']\n",
    "all_ann = c1sub.merge(c2sub,on=cols).merge(c3sub,on=cols).merge(c4sub,on=cols).merge(c5sub,on=cols).merge(c6sub,on=cols).merge(c7sub,on=cols).merge(c8sub,on=cols).merge(c9sub,on=cols).merge(c10sub,on=cols).merge(c11sub,on=cols)\n",
    "\n",
    "print(all_ann.shape)\n",
    "all_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate pairwise Cohen's kappa values \n",
    "\n",
    "c1_ann = all_ann.iloc[:,6]\n",
    "c2_ann = all_ann.iloc[:,7]\n",
    "c3_ann = all_ann.iloc[:,8]\n",
    "c4_ann = all_ann.iloc[:,9]\n",
    "c5_ann = all_ann.iloc[:,10]\n",
    "c6_ann = all_ann.iloc[:,11]\n",
    "c7_ann = all_ann.iloc[:,12]\n",
    "c8_ann = all_ann.iloc[:,13]\n",
    "c9_ann = all_ann.iloc[:,14]\n",
    "c10_ann = all_ann.iloc[:,15]\n",
    "c11_ann = all_ann.iloc[:,16]\n",
    "\n",
    "c1_c2 = round(cohen_kappa_score(c1_ann, c2_ann),2)\n",
    "c1_c3 = round(cohen_kappa_score(c1_ann, c3_ann),2)\n",
    "c1_c4 = round(cohen_kappa_score(c1_ann, c4_ann),2)\n",
    "c1_c5 = round(cohen_kappa_score(c1_ann, c5_ann),2)\n",
    "c1_c6 = round(cohen_kappa_score(c1_ann, c6_ann),2)\n",
    "c1_c7 = round(cohen_kappa_score(c1_ann, c7_ann),2)\n",
    "c1_c8 = round(cohen_kappa_score(c1_ann, c8_ann),2)\n",
    "c1_c9 = round(cohen_kappa_score(c1_ann, c9_ann),2)\n",
    "c1_c10 = round(cohen_kappa_score(c1_ann, c10_ann),2)\n",
    "c1_c11 = round(cohen_kappa_score(c1_ann, c11_ann),2)\n",
    "\n",
    "c2_c3 = round(cohen_kappa_score(c2_ann, c3_ann),2)\n",
    "c2_c4 = round(cohen_kappa_score(c2_ann, c4_ann),2)\n",
    "c2_c5 = round(cohen_kappa_score(c2_ann, c5_ann),2)\n",
    "c2_c6 = round(cohen_kappa_score(c2_ann, c6_ann),2)\n",
    "c2_c7 = round(cohen_kappa_score(c2_ann, c7_ann),2)\n",
    "c2_c8 = round(cohen_kappa_score(c2_ann, c8_ann),2)\n",
    "c2_c9 = round(cohen_kappa_score(c2_ann, c9_ann),2)\n",
    "c2_c10 = round(cohen_kappa_score(c2_ann, c10_ann),2)\n",
    "c2_c11 = round(cohen_kappa_score(c2_ann, c11_ann),2)\n",
    "\n",
    "c3_c4 = round(cohen_kappa_score(c3_ann, c4_ann),2)\n",
    "c3_c5 = round(cohen_kappa_score(c3_ann, c5_ann),2)\n",
    "c3_c6 = round(cohen_kappa_score(c3_ann, c6_ann),2)\n",
    "c3_c7 = round(cohen_kappa_score(c3_ann, c7_ann),2)\n",
    "c3_c8 = round(cohen_kappa_score(c3_ann, c8_ann),2)\n",
    "c3_c9 = round(cohen_kappa_score(c3_ann, c9_ann),2)\n",
    "c3_c10 = round(cohen_kappa_score(c3_ann, c10_ann),2)\n",
    "c3_c11 = round(cohen_kappa_score(c3_ann, c11_ann),2)\n",
    "\n",
    "c4_c5 = round(cohen_kappa_score(c4_ann, c5_ann),2)\n",
    "c4_c6 = round(cohen_kappa_score(c4_ann, c6_ann),2)\n",
    "c4_c7 = round(cohen_kappa_score(c4_ann, c7_ann),2)\n",
    "c4_c8 = round(cohen_kappa_score(c4_ann, c8_ann),2)\n",
    "c4_c9 = round(cohen_kappa_score(c4_ann, c9_ann),2)\n",
    "c4_c10 = round(cohen_kappa_score(c4_ann, c10_ann),2)\n",
    "c4_c11 = round(cohen_kappa_score(c4_ann, c11_ann),2)\n",
    "\n",
    "c5_c6 = round(cohen_kappa_score(c5_ann, c6_ann),2)\n",
    "c5_c7 = round(cohen_kappa_score(c5_ann, c7_ann),2)\n",
    "c5_c8 = round(cohen_kappa_score(c5_ann, c8_ann),2)\n",
    "c5_c9 = round(cohen_kappa_score(c5_ann, c9_ann),2)\n",
    "c5_c10 = round(cohen_kappa_score(c5_ann, c10_ann),2)\n",
    "c5_c11 = round(cohen_kappa_score(c5_ann, c11_ann),2)\n",
    "\n",
    "c6_c7 = round(cohen_kappa_score(c6_ann, c7_ann),2)\n",
    "c6_c8 = round(cohen_kappa_score(c6_ann, c8_ann),2)\n",
    "c6_c9 = round(cohen_kappa_score(c6_ann, c9_ann),2)\n",
    "c6_c10 = round(cohen_kappa_score(c6_ann, c10_ann),2)\n",
    "c6_c11 = round(cohen_kappa_score(c6_ann, c11_ann),2)\n",
    "\n",
    "c7_c8 = round(cohen_kappa_score(c7_ann, c8_ann),2)\n",
    "c7_c9 = round(cohen_kappa_score(c7_ann, c9_ann),2)\n",
    "c7_c10 = round(cohen_kappa_score(c7_ann, c10_ann),2)\n",
    "c7_c11 = round(cohen_kappa_score(c7_ann, c11_ann),2)\n",
    "\n",
    "c8_c9 = round(cohen_kappa_score(c8_ann, c9_ann),2)\n",
    "c8_c10 = round(cohen_kappa_score(c8_ann, c10_ann),2)\n",
    "c8_c11 = round(cohen_kappa_score(c8_ann, c11_ann),2)\n",
    "\n",
    "c9_c10 = round(cohen_kappa_score(c9_ann, c10_ann),2)\n",
    "c9_c11 = round(cohen_kappa_score(c9_ann, c11_ann),2)\n",
    "\n",
    "c10_c11 = round(cohen_kappa_score(c10_ann, c11_ann),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "C1 = [1.00, c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11]\n",
    "C2 = [\"\", 1.00, c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11]\n",
    "C3 = [\"\", \"\", 1.00, c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11]\n",
    "C4 = [\"\", \"\", \"\", 1.00, c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11]\n",
    "C5 = [\"\", \"\", \"\", \"\", 1.00, c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11]\n",
    "C6 = [\"\", \"\", \"\", \"\", \"\", 1.00, c6_c7, c6_c8, c6_c9, c6_c10, c6_c11]\n",
    "C7 = [\"\", \"\", \"\", \"\", \"\", \"\", 1.00, c7_c8, c7_c9, c7_c10, c7_c11]\n",
    "C8 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c8_c9, c8_c10, c8_c11]\n",
    "C9 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c9_c10, c9_c11]\n",
    "C10 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c10_c11]\n",
    "C11 = [\"\", \"\", \"\", \"\", \"\", \"\" , \"\", \"\", \"\", \"\", 1.00]\n",
    "\n",
    "C0 = pd.DataFrame(data=C0)\n",
    "C1 = pd.DataFrame(data=C1)\n",
    "C2 = pd.DataFrame(data=C2)\n",
    "C3 = pd.DataFrame(data=C3)\n",
    "C4 = pd.DataFrame(data=C4)\n",
    "C5 = pd.DataFrame(data=C5)\n",
    "C6 = pd.DataFrame(data=C6)\n",
    "C7 = pd.DataFrame(data=C7)\n",
    "C8 = pd.DataFrame(data=C8)\n",
    "C9 = pd.DataFrame(data=C9)\n",
    "C10 = pd.DataFrame(data=C10)\n",
    "C11 = pd.DataFrame(data=C11)\n",
    "\n",
    "C0.columns = [\"\"]\n",
    "C1.columns = ['C1']\n",
    "C2.columns = ['C2']\n",
    "C3.columns = ['C3']\n",
    "C4.columns = ['C4']\n",
    "C5.columns = ['C5']\n",
    "C6.columns = ['C6']\n",
    "C7.columns = ['C7']\n",
    "C8.columns = ['C8']\n",
    "C9.columns = ['C9']\n",
    "C10.columns = ['C10']\n",
    "C11.columns = ['C11']\n",
    "\n",
    "frames = [C0,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11]\n",
    "\n",
    "cohen_k = pd.concat(frames, axis=1)\n",
    "cohen_k = cohen_k.set_index(\"\")\n",
    "\n",
    "cols = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "cohen_k[cols] = cohen_k[cols].apply(pd.to_numeric)\n",
    "\n",
    "cohen_k.dtypes\n",
    "\n",
    "cohen_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pairwise Cohen's kappa\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "res = sns.heatmap(cohen_k, annot=True, vmin=0, vmax=1, \n",
    "                  fmt='.2f', cmap=\"YlGnBu\", annot_kws={\"fontsize\":15})\n",
    "\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 15)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Multi-RF-Exp1-Pairwise-Cohen's.png\")              \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find average pairwise Cohen's kappa \n",
    "\n",
    "pair_iaa = [c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11, \n",
    "          c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11, \n",
    "          c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11, \n",
    "          c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11, \n",
    "          c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11, \n",
    "          c6_c7, c6_c8, c6_c9, c6_c10, c6_c11, \n",
    "          c7_c8, c7_c9, c7_c10, c7_c11,\n",
    "          c8_c9, c8_c10, c8_c11, \n",
    "          c9_c10, c9_c11,  \n",
    "          c10_c11]\n",
    "\n",
    "print(len(pair_iaa))\n",
    "\n",
    "avg = round(mean(pair_iaa),3)\n",
    "sd = round(statistics.stdev(pair_iaa),3)\n",
    " \n",
    "# Prints average & standard deviation\n",
    "print(\"Average Cohen's kappa:\", avg)\n",
    "print(\"Standard Deviation:\", sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare C2, C4, C8 QEUH annotation distributions\n",
    "\n",
    "#C2\n",
    "c2_ann = all_ann['C2'].value_counts()\n",
    "c2_ann_dist = pd.DataFrame(data=c2_ann).reset_index()\n",
    "c2_ann_dist = c2_ann_dist.rename({'index':'QEUH Annotated Label'},axis=1)\n",
    "c2_ann_dist['C2 %'] = ((c2_ann_dist['C2']/60)*100)\n",
    "\n",
    "#C4\n",
    "c4_ann = all_ann['C4'].value_counts()\n",
    "c4_ann_dist = pd.DataFrame(data=c4_ann).reset_index()\n",
    "c4_ann_dist = c4_ann_dist.rename({'index':'QEUH Annotated Label'},axis=1)\n",
    "c4_ann_dist['C4 %'] = ((c4_ann_dist['C4']/60)*100)\n",
    "\n",
    "#C8\n",
    "c8_ann = all_ann['C8'].value_counts()\n",
    "c8_ann_dist = pd.DataFrame(data=c8_ann).reset_index()\n",
    "c8_ann_dist = c8_ann_dist.rename({'index':'QEUH Annotated Label'},axis=1)\n",
    "c8_ann_dist['C8 %'] = ((c8_ann_dist['C8']/60)*100)\n",
    "\n",
    "#merge\n",
    "\n",
    "ann_dist = c2_ann_dist.merge(c4_ann_dist, on='QEUH Annotated Label').merge(c8_ann_dist, on='QEUH Annotated Label')\n",
    "ann_dist = ann_dist.sort_values(by='QEUH Annotated Label', ascending=True)\n",
    "ann_dist = ann_dist.drop(['C2','C4','C8'], axis=1)\n",
    "\n",
    "ann_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Internal Validation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Parameter Grid for hyperparameter optimisation\n",
    "##Create a dictionary with all RF parameter options \n",
    "\n",
    "parameters = {'max_depth': [3, 4, 7, 9, 10, 20, 30, None], \n",
    "              'n_estimators': [10, 30, 50, 70, 100],\n",
    "              'criterion': ['gini','entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Function - RF Model Evaluation via 5-fold CV\n",
    "\n",
    "def do_cv_learning_rf(X, y, verbose=False, do_scale=False, random_state=1):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    f1s = []\n",
    "\n",
    "    if do_scale:\n",
    "        sc = StandardScaler()\n",
    "        X = sc.fit_transform(X)\n",
    "        \n",
    "    for i, (train,test) in enumerate(cv.split(X,y)):\n",
    "        gcsv = GridSearchCV(RandomForestClassifier(random_state=1), \n",
    "                            param_grid=parameters, \n",
    "                            cv=5, \n",
    "                            scoring='f1_micro')\n",
    "        grid_result = gcsv.fit(X[train],y[train])\n",
    "        best_params = grid_result.best_params_\n",
    "        if verbose:\n",
    "            print('fold', i,'best_params', best_params)\n",
    "        clf = grid_result.best_estimator_\n",
    "        f1 = metrics.f1_score(y[test], clf.predict(X[test]), average='micro')\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    ##Performance metrics \n",
    "    dfrf_multi_f1data = [['ann', 'multi', 'F1_micro', np.mean(f1s), np.std(f1s)]]\n",
    "\n",
    "    ##print data as DF\n",
    "    dfrf_multi_f1data = pd.DataFrame(data=dfrf_multi_f1data)\n",
    "    dfrf_multi_f1data.columns = ['Annotator','Model','Optimisation','F1_micro','S.D.']\n",
    "    \n",
    "    return dfrf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Function - Find highest performing model after 5-fold CV\n",
    "\n",
    "def model_opt_rf(X, y, verbose=False, do_scale=False, random_state=1):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    f1s = []\n",
    "    models = []\n",
    "\n",
    "    if do_scale:\n",
    "        sc = StandardScaler()\n",
    "        X = sc.fit_transform(X)\n",
    "        \n",
    "    for i, (train,test) in enumerate(cv.split(X,y)):\n",
    "        gcsv = GridSearchCV(RandomForestClassifier(random_state=1), \n",
    "                            param_grid=parameters, \n",
    "                            cv=5, \n",
    "                            scoring='f1_micro')\n",
    "        grid_result = gcsv.fit(X[train],y[train])\n",
    "        best_params = grid_result.best_params_\n",
    "        if verbose:\n",
    "            print('fold', i,'best_params', best_params)\n",
    "        clf = grid_result.best_estimator_\n",
    "        f1 = metrics.f1_score(y[test], clf.predict(X[test]), average='micro')\n",
    "        f1s.append(f1)\n",
    "        models.append(grid_result.best_estimator_)\n",
    "        \n",
    "    #find opt model\n",
    "    df_multi_opt = [f1s, models]\n",
    "    max_val = max(df_multi_opt[0])\n",
    "    max_index = df_multi_opt[0].index(max_val)\n",
    "    opt_model = df_multi_opt[1][max_index]\n",
    "    \n",
    "    return opt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Function - Find Feature Importances (FI)\n",
    "##FI indicates relative importance of each feature when making the classification \n",
    "\n",
    "def feat_imp(annrf_multi_opt):\n",
    "    \n",
    "    imp = list(annrf_multi_opt.feature_importances_)\n",
    "    \n",
    "    imp_data = [['ann', 'multi', 'F1', imp[0], imp[1], imp[2], imp[3], imp[4], imp[5]]]\n",
    "\n",
    "    #print data as DF\n",
    "    df_multi_imp = pd.DataFrame(data=imp_data)\n",
    "    df_multi_imp.columns = ['Annotator','Model','Optimisation','Adrenaline', 'Noradrenaline', 'FiO2', 'SpO2', 'Mean', \n",
    "                           'HR']\n",
    "    return df_multi_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C1 - IntVal\n",
    "\n",
    "array = c1.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c1rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c1rf_multi_f1data['Annotator'] = 'C1'\n",
    "\n",
    "#Find Opt model\n",
    "c1rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c1rf_opt_fi = feat_imp(c1rf_multi_opt)\n",
    "c1rf_opt_fi['Annotator'] = 'C1'\n",
    "\n",
    "print(c1rf_multi_opt)\n",
    "c1rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C2 - IntVal\n",
    "\n",
    "array = c2.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c2rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c2rf_multi_f1data['Annotator'] = 'C2'\n",
    "\n",
    "#Find Opt model\n",
    "c2rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c2rf_opt_fi = feat_imp(c2rf_multi_opt)\n",
    "c2rf_opt_fi['Annotator'] = 'C2'\n",
    "\n",
    "print(c2rf_multi_opt)\n",
    "c2rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C3 - IntVal\n",
    "\n",
    "array = c3.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c3rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c3rf_multi_f1data['Annotator'] = 'C3'\n",
    "\n",
    "#Find Opt model\n",
    "c3rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c3rf_opt_fi = feat_imp(c3rf_multi_opt)\n",
    "c3rf_opt_fi['Annotator'] = 'C3'\n",
    "\n",
    "print(c3rf_multi_opt)\n",
    "c3rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C4 - IntVal\n",
    "\n",
    "array = c4.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c4rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c4rf_multi_f1data['Annotator'] = 'C4'\n",
    "\n",
    "#Find Opt model\n",
    "c4rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c4rf_opt_fi = feat_imp(c4rf_multi_opt)\n",
    "c4rf_opt_fi['Annotator'] = 'C4'\n",
    "\n",
    "print(c4rf_multi_opt)\n",
    "c4rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C5 - IntVal\n",
    "\n",
    "array = c5.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c5rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c5rf_multi_f1data['Annotator'] = 'C5'\n",
    "\n",
    "#Find Opt model\n",
    "c5rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c5rf_opt_fi = feat_imp(c5rf_multi_opt)\n",
    "c5rf_opt_fi['Annotator'] = 'C5'\n",
    "\n",
    "print(c5rf_multi_opt)\n",
    "c5rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C6 - IntVal\n",
    "\n",
    "array = c6.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c6rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c6rf_multi_f1data['Annotator'] = 'C6'\n",
    "\n",
    "#Find Opt model\n",
    "c6rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c6rf_opt_fi = feat_imp(c6rf_multi_opt)\n",
    "c6rf_opt_fi['Annotator'] = 'C6'\n",
    "\n",
    "print(c6rf_multi_opt)\n",
    "c6rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C7 - IntVal\n",
    "\n",
    "array = c7.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c7rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c7rf_multi_f1data['Annotator'] = 'C7'\n",
    "\n",
    "#Find Opt model\n",
    "c7rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c7rf_opt_fi = feat_imp(c7rf_multi_opt)\n",
    "c7rf_opt_fi['Annotator'] = 'C7'\n",
    "\n",
    "print(c7rf_multi_opt)\n",
    "c7rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C8 - IntVal\n",
    "\n",
    "array = c8.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c8rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c8rf_multi_f1data['Annotator'] = 'C8'\n",
    "\n",
    "#Find Opt model\n",
    "c8rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c8rf_opt_fi = feat_imp(c8rf_multi_opt)\n",
    "c8rf_opt_fi['Annotator'] = 'C8'\n",
    "\n",
    "print(c8rf_multi_opt)\n",
    "c8rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C9 - IntVal\n",
    "\n",
    "array = c9.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c9rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c9rf_multi_f1data['Annotator'] = 'C9'\n",
    "\n",
    "#Find Opt model\n",
    "c9rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c9rf_opt_fi = feat_imp(c9rf_multi_opt)\n",
    "c9rf_opt_fi['Annotator'] = 'C9'\n",
    "\n",
    "print(c9rf_multi_opt)\n",
    "c9rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C10 - IntVal\n",
    "\n",
    "array = c10.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c10rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c10rf_multi_f1data['Annotator'] = 'C10'\n",
    "\n",
    "#Find Opt model\n",
    "c10rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c10rf_opt_fi = feat_imp(c10rf_multi_opt)\n",
    "c10rf_opt_fi['Annotator'] = 'C10'\n",
    "\n",
    "print(c10rf_multi_opt)\n",
    "c10rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C11 - IntVal\n",
    "\n",
    "array = c11.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "c11rf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "c11rf_multi_f1data['Annotator'] = 'C11'\n",
    "\n",
    "#Find Opt model\n",
    "c11rf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "c11rf_opt_fi = feat_imp(c11rf_multi_opt)\n",
    "c11rf_opt_fi['Annotator'] = 'C11'\n",
    "\n",
    "print(c11rf_multi_opt)\n",
    "c11rf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MV - IntVal\n",
    "\n",
    "array = mv.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "mvrf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "mvrf_multi_f1data['Annotator'] = 'MV'\n",
    "\n",
    "#Find Opt model\n",
    "mvrf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "mvrf_opt_fi = feat_imp(mvrf_multi_opt)\n",
    "mvrf_opt_fi['Annotator'] = 'MV'\n",
    "\n",
    "print(mvrf_multi_opt)\n",
    "mvrf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMV - IntVal\n",
    "\n",
    "array = tmv.to_numpy()\n",
    "X = array[:,0:6]  \n",
    "y = array[:,7]  \n",
    "\n",
    "X = X.astype(float) \n",
    "y = y.astype(int) \n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(le.classes_)\n",
    "\n",
    "#5-fold CV Model Eval\n",
    "tmvrf_multi_f1data = do_cv_learning_rf(X,y)\n",
    "tmvrf_multi_f1data['Annotator'] = 'TMV'\n",
    "\n",
    "#Find Opt model\n",
    "tmvrf_multi_opt = model_opt_rf(X,y)\n",
    "\n",
    "#Feature Importances\n",
    "tmvrf_opt_fi = feat_imp(tmvrf_multi_opt)\n",
    "tmvrf_opt_fi['Annotator'] = 'TMV'\n",
    "\n",
    "print(tmvrf_multi_opt)\n",
    "tmvrf_multi_f1data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Internal Validation Performances - Summary\n",
    "\n",
    "frames = [c1rf_multi_f1data, c2rf_multi_f1data, c3rf_multi_f1data, c4rf_multi_f1data, \n",
    "          c5rf_multi_f1data, c6rf_multi_f1data, c7rf_multi_f1data, c8rf_multi_f1data,\n",
    "          c9rf_multi_f1data, c10rf_multi_f1data, c11rf_multi_f1data, mvrf_multi_f1data,\n",
    "          tmvrf_multi_f1data]\n",
    "\n",
    "multi_int = pd.concat(frames)\n",
    "print(multi_int.shape)\n",
    "multi_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot chart - Internal Validation F1 (micro)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Define x and y data\n",
    "x1 = multi_int['Annotator']\n",
    "y1 = multi_int['F1_micro']\n",
    "\n",
    "#Plot chart data\n",
    "plt.figure(figsize=(8,2.5))\n",
    "plt.plot(x1, y1, color='#1F57C8', marker='o', linestyle=\"solid\", label='Multi')\n",
    "\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.yticks(np.arange(0.0,1.01, 0.2))\n",
    "\n",
    "#Add title and labels\n",
    "plt.title('Internal Validation: Multiclass - RF', fontsize=14)\n",
    "plt.xlabel('Annotator', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('F1_micro', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all Feature Importance data\n",
    "\n",
    "frames = [c1rf_opt_fi, c2rf_opt_fi, c3rf_opt_fi, c4rf_opt_fi, c5rf_opt_fi, c6rf_opt_fi,\n",
    "          c7rf_opt_fi, c8rf_opt_fi, c9rf_opt_fi, c10rf_opt_fi, c11rf_opt_fi]\n",
    "\n",
    "feat_imp = pd.concat(frames)\n",
    "\n",
    "print(feat_imp.shape)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Feature Importance \n",
    "\n",
    "##Set width of bars\n",
    "barwidth = 0.1\n",
    "\n",
    "labels = feat_imp['Annotator']\n",
    " \n",
    "##Set heights of bars\n",
    "Adrenaline = feat_imp['Adrenaline']\n",
    "Noradrenaline = feat_imp['Noradrenaline']\n",
    "FiO2 = feat_imp['FiO2']\n",
    "SpO2 = feat_imp['SpO2']\n",
    "Mean = feat_imp['Mean']\n",
    "HR = feat_imp['HR']\n",
    "\n",
    "##Set position of bar on X axis\n",
    "f1 = np.arange(len(Adrenaline))\n",
    "f2 = [x + barwidth for x in f1]\n",
    "f3 = [x + barwidth for x in f2]\n",
    "f4 = [x + barwidth for x in f3]\n",
    "f5 = [x + barwidth for x in f4]\n",
    "f6 = [x + barwidth for x in f5]\n",
    " \n",
    "##Make the plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1, FiO2, color='#1f77b4', width=barwidth,label='FiO2')\n",
    "plt.bar(f2, Noradrenaline, color='#CD534CFF', width=barwidth,label='Noradrenaline')\n",
    "plt.bar(f3, Mean, color='#9467BD', width=barwidth,label='Mean')\n",
    "plt.bar(f4, SpO2, color='#62B463', width=barwidth,label='SpO2')\n",
    "plt.bar(f5, Adrenaline, color='#FFA319FF', width=barwidth, label='Adrenaline')\n",
    "plt.bar(f6, HR, color='#8C564B', width=barwidth,label='HR')\n",
    " \n",
    "##Add xticks on the middle of the group bars\n",
    "plt.title('RF Classifiers - Feature Importances', fontsize=18)\n",
    "plt.xlabel('Annotator', fontsize=14)\n",
    "plt.ylabel('Feature Importance', fontsize=14)\n",
    "plt.xticks([r for r in range(len(Adrenaline))],labels,fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "##Set legend\n",
    "plt.legend(bbox_to_anchor=(1, 1), fontsize=14)\n",
    "\n",
    "##Save plot\n",
    "plt.savefig('Multi-RF-IntVal-F1-feat_imp.png', dpi=100)   \n",
    "    \n",
    "##Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. External Validation Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define HiRID External Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import HiRID 'Patient' table (contains discharge_status info)\n",
    "\n",
    "pat = pd.read_sql_query(\"SELECT * FROM hirid.patient\", conn)\n",
    "\n",
    "pat.to_csv('patient_table.csv')\n",
    "\n",
    "print(pat.shape)\n",
    "pat.head()\n",
    "\n",
    "#33,905 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import HiRID Validation Dataset - data for patients 1hr before discharge/death\n",
    "##See jupyter notebook 'npjDM-HiRID_ExtVal_Dataset' to see steps on creating this HiRID External Validation Dataset\n",
    "\n",
    "params1hr = pd.read_csv(\"HiRID_extval_params1hr.csv\")\n",
    "params1hr.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "params1hr['binary_status'] = np.where(params1hr['discharge_status']== 'alive', 0, 4)\n",
    "\n",
    "print(params1hr.shape)\n",
    "params1hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check dishcarge status classes are balanced\n",
    "\n",
    "params1hr.discharge_status.value_counts()\n",
    "params1hr.binary_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hirid validation dataset\n",
    "\n",
    "array = params1hr.to_numpy()\n",
    "X_test = array[:,3:9]  \n",
    "y_test = array[:,12]  \n",
    "\n",
    "X_test = X_test.astype(float) \n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Run QEUH models on HiRID External Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C1 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c1rf_multi_opt.predict(X_test), average='micro')\n",
    "c1rf_multi_ext  = [['C1', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c1rf_multi_ext = pd.DataFrame(data=c1rf_multi_ext)\n",
    "c1rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c1rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C1 - plot confusion matrix\n",
    "sns.reset_orig() \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c1rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c1rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "\n",
    "print(pred_labels)\n",
    "c1_A_pred = pred_labels[0]\n",
    "c1_B_pred = pred_labels[1]\n",
    "c1_C_pred = pred_labels[2]\n",
    "c1_D_pred = pred_labels[3]\n",
    "c1_E_pred = pred_labels[4]\n",
    "\n",
    "print(c1_A_pred,c1_B_pred,c1_C_pred,c1_D_pred,c1_E_pred)\n",
    "fig.savefig('confusion_matrix_c1.eps',format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C2 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c2rf_multi_opt.predict(X_test), average='micro')\n",
    "c2rf_multi_ext  = [['C2', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c2rf_multi_ext = pd.DataFrame(data=c2rf_multi_ext)\n",
    "c2rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c2rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C2 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c2rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c2rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c2_A_pred = pred_labels[0]\n",
    "c2_B_pred = pred_labels[1]\n",
    "c2_C_pred = pred_labels[2]\n",
    "c2_D_pred = pred_labels[3]\n",
    "c2_E_pred = pred_labels[4]\n",
    "print(c2_A_pred,c2_B_pred,c2_C_pred,c2_D_pred,c2_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C3 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c3rf_multi_opt.predict(X_test), average='micro')\n",
    "c3rf_multi_ext  = [['C3', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "##print data as DF\n",
    "c3rf_multi_ext = pd.DataFrame(data=c3rf_multi_ext)\n",
    "c3rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c3rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C3 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c3rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c3rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c3_A_pred = pred_labels[0]\n",
    "c3_B_pred = pred_labels[1]\n",
    "c3_C_pred = pred_labels[2]\n",
    "c3_D_pred = pred_labels[3]\n",
    "c3_E_pred = pred_labels[4]\n",
    "print(c3_A_pred,c3_B_pred,c3_C_pred,c3_D_pred,c3_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C4 - HiRID Ext val  \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c4rf_multi_opt.predict(X_test), average='micro')\n",
    "c4rf_multi_ext  = [['C4', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c4rf_multi_ext = pd.DataFrame(data=c4rf_multi_ext)\n",
    "c4rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c4rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C4 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c4rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c4rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c4_A_pred = pred_labels[0]\n",
    "c4_B_pred = pred_labels[1]\n",
    "c4_C_pred = pred_labels[2]\n",
    "c4_D_pred = pred_labels[3]\n",
    "c4_E_pred = pred_labels[4]\n",
    "print(c4_A_pred,c4_B_pred,c4_C_pred,c4_D_pred,c4_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C5 - HiRID Ext val  \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c5rf_multi_opt.predict(X_test), average='micro')\n",
    "c5rf_multi_ext  = [['C5', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c5rf_multi_ext = pd.DataFrame(data=c5rf_multi_ext)\n",
    "c5rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c5rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C5 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c5rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c5rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c5_A_pred = pred_labels[0]\n",
    "c5_B_pred = pred_labels[1]\n",
    "c5_C_pred = pred_labels[2]\n",
    "c5_D_pred = pred_labels[3]\n",
    "c5_E_pred = pred_labels[4]\n",
    "print(c5_A_pred,c5_B_pred,c5_C_pred,c5_D_pred,c5_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C6 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c6rf_multi_opt.predict(X_test), average='micro')\n",
    "c6rf_multi_ext  = [['C6', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c6rf_multi_ext = pd.DataFrame(data=c6rf_multi_ext)\n",
    "c6rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c6rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C6 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c6rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c6rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c6_A_pred = pred_labels[0]\n",
    "c6_B_pred = pred_labels[1]\n",
    "c6_C_pred = pred_labels[2]\n",
    "c6_D_pred = pred_labels[3]\n",
    "c6_E_pred = pred_labels[4]\n",
    "print(c6_A_pred,c6_B_pred,c6_C_pred,c6_D_pred,c6_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C7 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c7rf_multi_opt.predict(X_test), average='micro')\n",
    "c7rf_multi_ext  = [['C7', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c7rf_multi_ext = pd.DataFrame(data=c7rf_multi_ext)\n",
    "c7rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c7rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C7 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c7rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c7rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c7_A_pred = pred_labels[0]\n",
    "c7_B_pred = pred_labels[1]\n",
    "c7_C_pred = pred_labels[2]\n",
    "c7_D_pred = pred_labels[3]\n",
    "c7_E_pred = pred_labels[4]\n",
    "print(c7_A_pred,c7_B_pred,c7_C_pred,c7_D_pred,c7_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C8 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c8rf_multi_opt.predict(X_test), average='micro')\n",
    "c8rf_multi_ext  = [['C8', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c8rf_multi_ext = pd.DataFrame(data=c8rf_multi_ext)\n",
    "c8rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c8rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C8 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c8rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c8rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c8_A_pred = pred_labels[0]\n",
    "c8_B_pred = pred_labels[1]\n",
    "c8_C_pred = pred_labels[2]\n",
    "c8_D_pred = pred_labels[3]\n",
    "c8_E_pred = pred_labels[4]\n",
    "print(c8_A_pred,c8_B_pred,c8_C_pred,c8_D_pred,c8_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C9 - HiRID Ext val  \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c9rf_multi_opt.predict(X_test), average='micro')\n",
    "c9rf_multi_ext  = [['C9', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c9rf_multi_ext = pd.DataFrame(data=c9rf_multi_ext)\n",
    "c9rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c9rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C9 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c9rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c9rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c9_A_pred = pred_labels[0]\n",
    "c9_B_pred = pred_labels[1]\n",
    "c9_C_pred = pred_labels[2]\n",
    "c9_D_pred = pred_labels[3]\n",
    "c9_E_pred = pred_labels[4]\n",
    "print(c9_A_pred,c9_B_pred,c9_C_pred,c9_D_pred,c9_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C10 - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c10rf_multi_opt.predict(X_test), average='micro')\n",
    "c10rf_multi_ext  = [['C10', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c10rf_multi_ext = pd.DataFrame(data=c10rf_multi_ext)\n",
    "c10rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c10rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C10 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c10rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c10rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c10_A_pred = pred_labels[0]\n",
    "c10_B_pred = pred_labels[1]\n",
    "c10_C_pred = pred_labels[2]\n",
    "c10_D_pred = pred_labels[3]\n",
    "c10_E_pred = pred_labels[4]\n",
    "print(c10_A_pred,c10_B_pred,c10_C_pred,c10_D_pred,c10_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C11- HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), c11rf_multi_opt.predict(X_test), average='micro')\n",
    "c11rf_multi_ext  = [['C11', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "c11rf_multi_ext = pd.DataFrame(data=c11rf_multi_ext)\n",
    "c11rf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "c11rf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C11 - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(c11rf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), c11rf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "c11_A_pred = pred_labels[0]\n",
    "c11_B_pred = pred_labels[1]\n",
    "c11_C_pred = pred_labels[2]\n",
    "c11_D_pred = pred_labels[3]\n",
    "c11_E_pred = pred_labels[4]\n",
    "print(c11_A_pred,c11_B_pred,c11_C_pred,c11_D_pred,c11_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MV - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), mvrf_multi_opt.predict(X_test), average='micro')\n",
    "mvrf_multi_ext  = [['MV', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "mvrf_multi_ext = pd.DataFrame(data=mvrf_multi_ext)\n",
    "mvrf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "mvrf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MV - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(mvrf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)\n",
    "\n",
    "cnf_matrix = confusion_matrix(list(y_test), mvrf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "mv_A_pred = pred_labels[0]\n",
    "mv_B_pred = pred_labels[1]\n",
    "mv_C_pred = pred_labels[2]\n",
    "mv_D_pred = pred_labels[3]\n",
    "mv_E_pred = pred_labels[4]\n",
    "print(mv_A_pred,mv_B_pred,mv_C_pred,mv_D_pred,mv_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMV - HiRID Ext val \n",
    "\n",
    "f1 = metrics.f1_score(list(y_test), tmvrf_multi_opt.predict(X_test), average='micro')\n",
    "tmvrf_multi_ext  = [['TMV', 'multi', 'F1_micro', f1]]\n",
    "\n",
    "tmvrf_multi_ext = pd.DataFrame(data=tmvrf_multi_ext)\n",
    "tmvrf_multi_ext.columns = ['Annotator','Model','Optimisation','F1_micro']\n",
    "tmvrf_multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMV - plot confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "disp = plot_confusion_matrix(tmvrf_multi_opt, X_test, list(y_test),\n",
    "                             cmap=plt.cm.Blues, colorbar=False,\n",
    "                             ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate above ValueError\n",
    "\n",
    "set(tmvrf_multi_opt.predict(X_test))\n",
    "\n",
    "#TMV predicted labels contain no '3' labels (i.e. no 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(list(y_test), tmvrf_multi_opt.predict(X_test))\n",
    "pred_labels = cnf_matrix.sum(axis=0)\n",
    "print(pred_labels)\n",
    "\n",
    "tmv_A_pred = pred_labels[0]\n",
    "tmv_B_pred = pred_labels[1]\n",
    "tmv_C_pred = pred_labels[2]\n",
    "tmv_D_pred = 0\n",
    "tmv_E_pred = pred_labels[3]\n",
    "\n",
    "print(tmv_A_pred,tmv_B_pred,tmv_C_pred,tmv_D_pred, tmv_E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#External Validation - Summary\n",
    "\n",
    "frames = [c1rf_multi_ext, c2rf_multi_ext, c3rf_multi_ext, c4rf_multi_ext, \n",
    "          c5rf_multi_ext, c6rf_multi_ext, c7rf_multi_ext, c8rf_multi_ext,\n",
    "          c9rf_multi_ext, c10rf_multi_ext, c11rf_multi_ext, mvrf_multi_ext,\n",
    "          tmvrf_multi_ext]\n",
    "\n",
    "multi_ext = pd.concat(frames)\n",
    "\n",
    "print(multi_ext.shape)\n",
    "multi_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#External Validation Performance - Consultant Models\n",
    "\n",
    "frames = [c1rf_multi_ext, c2rf_multi_ext, c3rf_multi_ext, c4rf_multi_ext, \n",
    "          c5rf_multi_ext, c6rf_multi_ext, c7rf_multi_ext, c8rf_multi_ext,\n",
    "          c9rf_multi_ext, c10rf_multi_ext, c11rf_multi_ext]\n",
    "\n",
    "multi_ext_ann = pd.concat(frames)\n",
    "\n",
    "print(multi_ext_ann.shape)\n",
    "multi_ext_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#External Validation Performance - Majority Vote Models\n",
    "\n",
    "frames = [mvrf_multi_ext, tmvrf_multi_ext]\n",
    "\n",
    "multi_ext_mvs = pd.concat(frames)\n",
    "print(multi_ext_mvs.shape)\n",
    "multi_ext_mvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot chart - External Validation\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "#Define x and y data\n",
    "x1 = multi_ext_ann['Annotator']\n",
    "y1 = multi_ext_ann['F1_micro']\n",
    "mv = multi_ext_mvs.iloc[0,3]\n",
    "tmv = multi_ext_mvs.iloc[1,3]\n",
    "\n",
    "#Plot chart data\n",
    "plt.figure(figsize=(8.5,3.5))\n",
    "plt.plot(x1, y1, color='#1F57C8', marker='o', linestyle=\"solid\")\n",
    "plt.ylim([0.0,0.61])\n",
    "plt.yticks(np.arange(0.0,0.61, 0.1))\n",
    "plt.axhline(y=mv, color='#DA4802', linestyle='-', label = 'Majority Vote (MV)')\n",
    "plt.axhline(y=tmv, color='#65C314', linestyle='-', label = 'Top Majority Vote (TMV)')\n",
    "\n",
    "#Add title and labels\n",
    "plt.xlabel('Annotator', fontsize=14, labelpad=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('F1 micro', fontsize=14, labelpad=10)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12, loc='upper center',  bbox_to_anchor=(0.5, -0.35), fancybox=False, shadow=False, ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "#Save plot\n",
    "plt.savefig('Figure_6.eps', format='eps')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 External Validation - IAA Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consistency of predicted labels\n",
    "\n",
    "c1_lab = pd.DataFrame(c1rf_multi_opt.predict(X_test).T)\n",
    "c1_lab.columns =['C1']\n",
    "\n",
    "c2_lab = pd.DataFrame(c2rf_multi_opt.predict(X_test).T)\n",
    "c2_lab.columns =['C2']\n",
    "\n",
    "c3_lab = pd.DataFrame(c3rf_multi_opt.predict(X_test).T)\n",
    "c3_lab.columns =['C3']\n",
    "\n",
    "c4_lab = pd.DataFrame(c4rf_multi_opt.predict(X_test).T)\n",
    "c4_lab.columns =['C4']\n",
    "\n",
    "c5_lab = pd.DataFrame(c5rf_multi_opt.predict(X_test).T)\n",
    "c5_lab.columns =['C5']\n",
    "\n",
    "c6_lab = pd.DataFrame(c6rf_multi_opt.predict(X_test).T)\n",
    "c6_lab.columns =['C6']\n",
    "\n",
    "c7_lab = pd.DataFrame(c7rf_multi_opt.predict(X_test).T)\n",
    "c7_lab.columns =['C7']\n",
    "\n",
    "c8_lab = pd.DataFrame(c8rf_multi_opt.predict(X_test).T)\n",
    "c8_lab.columns =['C8']\n",
    "\n",
    "c9_lab = pd.DataFrame(c9rf_multi_opt.predict(X_test).T)\n",
    "c9_lab.columns =['C9']\n",
    "\n",
    "c10_lab = pd.DataFrame(c10rf_multi_opt.predict(X_test).T)\n",
    "c10_lab.columns =['C10']\n",
    "\n",
    "c11_lab = pd.DataFrame(c11rf_multi_opt.predict(X_test).T)\n",
    "c11_lab.columns =['C11']\n",
    "\n",
    "true_lab = pd.DataFrame(y_test.T)\n",
    "true_lab.columns =['True_label']\n",
    "\n",
    "frames = [c1_lab, c2_lab, c3_lab, c4_lab, c5_lab, c6_lab, c7_lab, c8_lab, c9_lab, c10_lab, c11_lab, true_lab]\n",
    "\n",
    "pred_lab = pd.concat(frames, axis=1)\n",
    "pred_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Discharged Alive - IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only Discharged alive\n",
    "\n",
    "true_alive = pred_lab.copy(deep=True)\n",
    "true_alive = true_alive[true_alive['True_label']==0]\n",
    "true_alive = true_alive.drop('True_label', axis = 1)\n",
    "true_alive = true_alive.applymap(str)\n",
    "true_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate pairwise Cohen's kappa (Discharged Alive only)\n",
    "\n",
    "c1_pred = true_alive.iloc[:,0]\n",
    "c2_pred = true_alive.iloc[:,1]\n",
    "c3_pred = true_alive.iloc[:,2]\n",
    "c4_pred = true_alive.iloc[:,3]\n",
    "c5_pred = true_alive.iloc[:,4]\n",
    "c6_pred = true_alive.iloc[:,5]\n",
    "c7_pred = true_alive.iloc[:,6]\n",
    "c8_pred = true_alive.iloc[:,7]\n",
    "c9_pred = true_alive.iloc[:,8]\n",
    "c10_pred = true_alive.iloc[:,9]\n",
    "c11_pred = true_alive.iloc[:,10]\n",
    "\n",
    "c1_c2 = round(cohen_kappa_score(c1_pred, c2_pred),2)\n",
    "c1_c3 = round(cohen_kappa_score(c1_pred, c3_pred),2)\n",
    "c1_c4 = round(cohen_kappa_score(c1_pred, c4_pred),2)\n",
    "c1_c5 = round(cohen_kappa_score(c1_pred, c5_pred),2)\n",
    "c1_c6 = round(cohen_kappa_score(c1_pred, c6_pred),2)\n",
    "c1_c7 = round(cohen_kappa_score(c1_pred, c7_pred),2)\n",
    "c1_c8 = round(cohen_kappa_score(c1_pred, c8_pred),2)\n",
    "c1_c9 = round(cohen_kappa_score(c1_pred, c9_pred),2)\n",
    "c1_c10 = round(cohen_kappa_score(c1_pred, c10_pred),2)\n",
    "c1_c11 = round(cohen_kappa_score(c1_pred, c11_pred),2)\n",
    "\n",
    "c2_c3 = round(cohen_kappa_score(c2_pred, c3_pred),2)\n",
    "c2_c4 = round(cohen_kappa_score(c2_pred, c4_pred),2)\n",
    "c2_c5 = round(cohen_kappa_score(c2_pred, c5_pred),2)\n",
    "c2_c6 = round(cohen_kappa_score(c2_pred, c6_pred),2)\n",
    "c2_c7 = round(cohen_kappa_score(c2_pred, c7_pred),2)\n",
    "c2_c8 = round(cohen_kappa_score(c2_pred, c8_pred),2)\n",
    "c2_c9 = round(cohen_kappa_score(c2_pred, c9_pred),2)\n",
    "c2_c10 = round(cohen_kappa_score(c2_pred, c10_pred),2)\n",
    "c2_c11 = round(cohen_kappa_score(c2_pred, c11_pred),2)\n",
    "\n",
    "c3_c4 = round(cohen_kappa_score(c3_pred, c4_pred),2)\n",
    "c3_c5 = round(cohen_kappa_score(c3_pred, c5_pred),2)\n",
    "c3_c6 = round(cohen_kappa_score(c3_pred, c6_pred),2)\n",
    "c3_c7 = round(cohen_kappa_score(c3_pred, c7_pred),2)\n",
    "c3_c8 = round(cohen_kappa_score(c3_pred, c8_pred),2)\n",
    "c3_c9 = round(cohen_kappa_score(c3_pred, c9_pred),2)\n",
    "c3_c10 = round(cohen_kappa_score(c3_pred, c10_pred),2)\n",
    "c3_c11 = round(cohen_kappa_score(c3_pred, c11_pred),2)\n",
    "\n",
    "c4_c5 = round(cohen_kappa_score(c4_pred, c5_pred),2)\n",
    "c4_c6 = round(cohen_kappa_score(c4_pred, c6_pred),2)\n",
    "c4_c7 = round(cohen_kappa_score(c4_pred, c7_pred),2)\n",
    "c4_c8 = round(cohen_kappa_score(c4_pred, c8_pred),2)\n",
    "c4_c9 = round(cohen_kappa_score(c4_pred, c9_pred),2)\n",
    "c4_c10 = round(cohen_kappa_score(c4_pred, c10_pred),2)\n",
    "c4_c11 = round(cohen_kappa_score(c4_pred, c11_pred),2)\n",
    "\n",
    "c5_c6 = round(cohen_kappa_score(c5_pred, c6_pred),2)\n",
    "c5_c7 = round(cohen_kappa_score(c5_pred, c7_pred),2)\n",
    "c5_c8 = round(cohen_kappa_score(c5_pred, c8_pred),2)\n",
    "c5_c9 = round(cohen_kappa_score(c5_pred, c9_pred),2)\n",
    "c5_c10 = round(cohen_kappa_score(c5_pred, c10_pred),2)\n",
    "c5_c11 = round(cohen_kappa_score(c5_pred, c11_pred),2)\n",
    "\n",
    "c6_c7 = round(cohen_kappa_score(c6_pred, c7_pred),2)\n",
    "c6_c8 = round(cohen_kappa_score(c6_pred, c8_pred),2)\n",
    "c6_c9 = round(cohen_kappa_score(c6_pred, c9_pred),2)\n",
    "c6_c10 = round(cohen_kappa_score(c6_pred, c10_pred),2)\n",
    "c6_c11 = round(cohen_kappa_score(c6_pred, c11_pred),2)\n",
    "\n",
    "c7_c8 = round(cohen_kappa_score(c7_pred, c8_pred),2)\n",
    "c7_c9 = round(cohen_kappa_score(c7_pred, c9_pred),2)\n",
    "c7_c10 = round(cohen_kappa_score(c7_pred, c10_pred),2)\n",
    "c7_c11 = round(cohen_kappa_score(c7_pred, c11_pred),2)\n",
    "\n",
    "c8_c9 = round(cohen_kappa_score(c8_pred, c9_pred),2)\n",
    "c8_c10 = round(cohen_kappa_score(c8_pred, c10_pred),2)\n",
    "c8_c11 = round(cohen_kappa_score(c8_pred, c11_pred),2)\n",
    "\n",
    "c9_c10 = round(cohen_kappa_score(c9_pred, c10_pred),2)\n",
    "c9_c11 = round(cohen_kappa_score(c9_pred, c11_pred),2)\n",
    "\n",
    "c10_c11 = round(cohen_kappa_score(c10_pred, c11_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairwise Cohen's kappa (Discharged Alive only)\n",
    "\n",
    "C0 = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "C1 = [1.00, c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11]\n",
    "C2 = [\"\", 1.00, c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11]\n",
    "C3 = [\"\", \"\", 1.00, c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11]\n",
    "C4 = [\"\", \"\", \"\", 1.00, c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11]\n",
    "C5 = [\"\", \"\", \"\", \"\", 1.00, c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11]\n",
    "C6 = [\"\", \"\", \"\", \"\", \"\", 1.00, c6_c7, c6_c8, c6_c9, c6_c10, c6_c11]\n",
    "C7 = [\"\", \"\", \"\", \"\", \"\", \"\", 1.00, c7_c8, c7_c9, c7_c10, c7_c11]\n",
    "C8 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c8_c9, c8_c10, c8_c11]\n",
    "C9 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c9_c10, c9_c11]\n",
    "C10 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c10_c11]\n",
    "C11 = [\"\", \"\", \"\", \"\", \"\", \"\" , \"\", \"\", \"\", \"\", 1.00]\n",
    "\n",
    "C0 = pd.DataFrame(data=C0)\n",
    "C1 = pd.DataFrame(data=C1)\n",
    "C2 = pd.DataFrame(data=C2)\n",
    "C3 = pd.DataFrame(data=C3)\n",
    "C4 = pd.DataFrame(data=C4)\n",
    "C5 = pd.DataFrame(data=C5)\n",
    "C6 = pd.DataFrame(data=C6)\n",
    "C7 = pd.DataFrame(data=C7)\n",
    "C8 = pd.DataFrame(data=C8)\n",
    "C9 = pd.DataFrame(data=C9)\n",
    "C10 = pd.DataFrame(data=C10)\n",
    "C11 = pd.DataFrame(data=C11)\n",
    "\n",
    "C0.columns = [\"\"]\n",
    "C1.columns = ['C1']\n",
    "C2.columns = ['C2']\n",
    "C3.columns = ['C3']\n",
    "C4.columns = ['C4']\n",
    "C5.columns = ['C5']\n",
    "C6.columns = ['C6']\n",
    "C7.columns = ['C7']\n",
    "C8.columns = ['C8']\n",
    "C9.columns = ['C9']\n",
    "C10.columns = ['C10']\n",
    "C11.columns = ['C11']\n",
    "\n",
    "frames = [C0,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11]\n",
    "\n",
    "cohen_k = pd.concat(frames, axis=1)\n",
    "cohen_k = cohen_k.set_index(\"\")\n",
    "\n",
    "cohen_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pairwise Cohen's kappa (Discharged Alive only)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "cols = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "cohen_k[cols] = cohen_k[cols].apply(pd.to_numeric)\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "res = sns.heatmap(cohen_k, annot=True, vmin=0, vmax=1,\n",
    "                  fmt='.2f', cmap=\"YlGnBu\", annot_kws={\"fontsize\":14})\n",
    "\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 15)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('confusion_matrix_c1.eps',format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average pairwise cohen's kappa values (Discharge alived)\n",
    "import statistics\n",
    "from statistics import mean\n",
    " \n",
    "#data\n",
    "sample = [c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11,\n",
    "          c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11,\n",
    "          c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11, \n",
    "          c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11, \n",
    "          c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11,  \n",
    "          c6_c7, c6_c8, c6_c9, c6_c10, c6_c11, \n",
    "          c7_c8, c7_c9, c7_c10, c7_c11,  \n",
    "          c8_c9, c8_c10, c8_c11,  \n",
    "          c9_c10, c9_c11,  \n",
    "          c10_c11]\n",
    "\n",
    "avg = round(mean(sample),3)\n",
    "sd = round(statistics.stdev(sample),3)\n",
    " \n",
    "# Prints average & standard deviation\n",
    "print(\"Average:\", avg)\n",
    "print(\"Standard Deviation:\", sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Fleiss' kappa for Discharged Alive\n",
    "\n",
    "all_alive = true_alive.copy(deep=True)\n",
    "all_alive['count_A']  = all_alive.eq('0').sum(axis=1)\n",
    "all_alive['count_B']  = all_alive.eq('1').sum(axis=1)\n",
    "all_alive['count_C']  = all_alive.eq('2').sum(axis=1)\n",
    "all_alive['count_D']  = all_alive.eq('3').sum(axis=1)\n",
    "all_alive['count_E']  = all_alive.eq('4').sum(axis=1)\n",
    "\n",
    "##drop unncessary cols\n",
    "cols = [ 'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11']\n",
    "\n",
    "all_alive = all_alive.drop(cols, axis = 1)\n",
    "\n",
    "all_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Fleiss' kappa - Discharged Alive\n",
    "\n",
    "fleiss_k = round(fleiss_kappa(all_alive, method='fleiss'),3)\n",
    "\n",
    "print(\"Fleiss' kappa: {:.3f}\".format(fleiss_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Died in ICU - IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only Discharged died\n",
    "\n",
    "true_died = pred_lab.copy(deep=True)\n",
    "true_died = true_died[true_died['True_label']==4]\n",
    "true_died = true_died.drop('True_label', axis = 1)\n",
    "true_died = true_died.applymap(str)\n",
    "true_died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate pairwise Cohen's kappa (Died only)\n",
    "\n",
    "c1_pred = true_died.iloc[:,0]\n",
    "c2_pred = true_died.iloc[:,1]\n",
    "c3_pred = true_died.iloc[:,2]\n",
    "c4_pred = true_died.iloc[:,3]\n",
    "c5_pred = true_died.iloc[:,4]\n",
    "c6_pred = true_died.iloc[:,5]\n",
    "c7_pred = true_died.iloc[:,6]\n",
    "c8_pred = true_died.iloc[:,7]\n",
    "c9_pred = true_died.iloc[:,8]\n",
    "c10_pred = true_died.iloc[:,9]\n",
    "c11_pred = true_died.iloc[:,10]\n",
    "\n",
    "c1_c2 = round(cohen_kappa_score(c1_pred, c2_pred),2)\n",
    "c1_c3 = round(cohen_kappa_score(c1_pred, c3_pred),2)\n",
    "c1_c4 = round(cohen_kappa_score(c1_pred, c4_pred),2)\n",
    "c1_c5 = round(cohen_kappa_score(c1_pred, c5_pred),2)\n",
    "c1_c6 = round(cohen_kappa_score(c1_pred, c6_pred),2)\n",
    "c1_c7 = round(cohen_kappa_score(c1_pred, c7_pred),2)\n",
    "c1_c8 = round(cohen_kappa_score(c1_pred, c8_pred),2)\n",
    "c1_c9 = round(cohen_kappa_score(c1_pred, c9_pred),2)\n",
    "c1_c10 = round(cohen_kappa_score(c1_pred, c10_pred),2)\n",
    "c1_c11 = round(cohen_kappa_score(c1_pred, c11_pred),2)\n",
    "\n",
    "c2_c3 = round(cohen_kappa_score(c2_pred, c3_pred),2)\n",
    "c2_c4 = round(cohen_kappa_score(c2_pred, c4_pred),2)\n",
    "c2_c5 = round(cohen_kappa_score(c2_pred, c5_pred),2)\n",
    "c2_c6 = round(cohen_kappa_score(c2_pred, c6_pred),2)\n",
    "c2_c7 = round(cohen_kappa_score(c2_pred, c7_pred),2)\n",
    "c2_c8 = round(cohen_kappa_score(c2_pred, c8_pred),2)\n",
    "c2_c9 = round(cohen_kappa_score(c2_pred, c9_pred),2)\n",
    "c2_c10 = round(cohen_kappa_score(c2_pred, c10_pred),2)\n",
    "c2_c11 = round(cohen_kappa_score(c2_pred, c11_pred),2)\n",
    "\n",
    "c3_c4 = round(cohen_kappa_score(c3_pred, c4_pred),2)\n",
    "c3_c5 = round(cohen_kappa_score(c3_pred, c5_pred),2)\n",
    "c3_c6 = round(cohen_kappa_score(c3_pred, c6_pred),2)\n",
    "c3_c7 = round(cohen_kappa_score(c3_pred, c7_pred),2)\n",
    "c3_c8 = round(cohen_kappa_score(c3_pred, c8_pred),2)\n",
    "c3_c9 = round(cohen_kappa_score(c3_pred, c9_pred),2)\n",
    "c3_c10 = round(cohen_kappa_score(c3_pred, c10_pred),2)\n",
    "c3_c11 = round(cohen_kappa_score(c3_pred, c11_pred),2)\n",
    "\n",
    "c4_c5 = round(cohen_kappa_score(c4_pred, c5_pred),2)\n",
    "c4_c6 = round(cohen_kappa_score(c4_pred, c6_pred),2)\n",
    "c4_c7 = round(cohen_kappa_score(c4_pred, c7_pred),2)\n",
    "c4_c8 = round(cohen_kappa_score(c4_pred, c8_pred),2)\n",
    "c4_c9 = round(cohen_kappa_score(c4_pred, c9_pred),2)\n",
    "c4_c10 = round(cohen_kappa_score(c4_pred, c10_pred),2)\n",
    "c4_c11 = round(cohen_kappa_score(c4_pred, c11_pred),2)\n",
    "\n",
    "c5_c6 = round(cohen_kappa_score(c5_pred, c6_pred),2)\n",
    "c5_c7 = round(cohen_kappa_score(c5_pred, c7_pred),2)\n",
    "c5_c8 = round(cohen_kappa_score(c5_pred, c8_pred),2)\n",
    "c5_c9 = round(cohen_kappa_score(c5_pred, c9_pred),2)\n",
    "c5_c10 = round(cohen_kappa_score(c5_pred, c10_pred),2)\n",
    "c5_c11 = round(cohen_kappa_score(c5_pred, c11_pred),2)\n",
    "\n",
    "c6_c7 = round(cohen_kappa_score(c6_pred, c7_pred),2)\n",
    "c6_c8 = round(cohen_kappa_score(c6_pred, c8_pred),2)\n",
    "c6_c9 = round(cohen_kappa_score(c6_pred, c9_pred),2)\n",
    "c6_c10 = round(cohen_kappa_score(c6_pred, c10_pred),2)\n",
    "c6_c11 = round(cohen_kappa_score(c6_pred, c11_pred),2)\n",
    "\n",
    "c7_c8 = round(cohen_kappa_score(c7_pred, c8_pred),2)\n",
    "c7_c9 = round(cohen_kappa_score(c7_pred, c9_pred),2)\n",
    "c7_c10 = round(cohen_kappa_score(c7_pred, c10_pred),2)\n",
    "c7_c11 = round(cohen_kappa_score(c7_pred, c11_pred),2)\n",
    "\n",
    "c8_c9 = round(cohen_kappa_score(c8_pred, c9_pred),2)\n",
    "c8_c10 = round(cohen_kappa_score(c8_pred, c10_pred),2)\n",
    "c8_c11 = round(cohen_kappa_score(c8_pred, c11_pred),2)\n",
    "\n",
    "c9_c10 = round(cohen_kappa_score(c9_pred, c10_pred),2)\n",
    "c9_c11 = round(cohen_kappa_score(c9_pred, c11_pred),2)\n",
    "\n",
    "c10_c11 = round(cohen_kappa_score(c10_pred, c11_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairwise Cohen's kappa (Died only)\n",
    "\n",
    "C0 = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "C1 = [1.00, c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11]\n",
    "C2 = [\"\", 1.00, c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11]\n",
    "C3 = [\"\", \"\", 1.00, c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11]\n",
    "C4 = [\"\", \"\", \"\", 1.00, c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11]\n",
    "C5 = [\"\", \"\", \"\", \"\", 1.00, c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11]\n",
    "C6 = [\"\", \"\", \"\", \"\", \"\", 1.00, c6_c7, c6_c8, c6_c9, c6_c10, c6_c11]\n",
    "C7 = [\"\", \"\", \"\", \"\", \"\", \"\", 1.00, c7_c8, c7_c9, c7_c10, c7_c11]\n",
    "C8 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c8_c9, c8_c10, c8_c11]\n",
    "C9 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c9_c10, c9_c11]\n",
    "C10 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c10_c11]\n",
    "C11 = [\"\", \"\", \"\", \"\", \"\", \"\" , \"\", \"\", \"\", \"\", 1.00]\n",
    "\n",
    "C0 = pd.DataFrame(data=C0)\n",
    "C1 = pd.DataFrame(data=C1)\n",
    "C2 = pd.DataFrame(data=C2)\n",
    "C3 = pd.DataFrame(data=C3)\n",
    "C4 = pd.DataFrame(data=C4)\n",
    "C5 = pd.DataFrame(data=C5)\n",
    "C6 = pd.DataFrame(data=C6)\n",
    "C7 = pd.DataFrame(data=C7)\n",
    "C8 = pd.DataFrame(data=C8)\n",
    "C9 = pd.DataFrame(data=C9)\n",
    "C10 = pd.DataFrame(data=C10)\n",
    "C11 = pd.DataFrame(data=C11)\n",
    "\n",
    "C0.columns = [\"\"]\n",
    "C1.columns = ['C1']\n",
    "C2.columns = ['C2']\n",
    "C3.columns = ['C3']\n",
    "C4.columns = ['C4']\n",
    "C5.columns = ['C5']\n",
    "C6.columns = ['C6']\n",
    "C7.columns = ['C7']\n",
    "C8.columns = ['C8']\n",
    "C9.columns = ['C9']\n",
    "C10.columns = ['C10']\n",
    "C11.columns = ['C11']\n",
    "\n",
    "frames = [C0,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11]\n",
    "\n",
    "cohen_k = pd.concat(frames, axis=1)\n",
    "cohen_k = cohen_k.set_index(\"\")\n",
    "\n",
    "cohen_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pairwise Cohen's kappa (Died only)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "cols = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "cohen_k[cols] = cohen_k[cols].apply(pd.to_numeric)\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(7, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "res = sns.heatmap(cohen_k, annot=True, vmin=0, vmax=1, cbar=False,\n",
    "                  fmt='.2f', cmap=\"YlGnBu\", annot_kws={\"fontsize\":15})\n",
    "\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 15)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#range cohen's k:0.01 to 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average pairwise cohen's kappa values (Died)\n",
    "import statistics\n",
    "from statistics import mean\n",
    " \n",
    "#data\n",
    "sample = [c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11,\n",
    "          c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11,\n",
    "          c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11, \n",
    "          c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11, \n",
    "          c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11,  \n",
    "          c6_c7, c6_c8, c6_c9, c6_c10, c6_c11, \n",
    "          c7_c8, c7_c9, c7_c10, c7_c11,  \n",
    "          c8_c9, c8_c10, c8_c11,  \n",
    "          c9_c10, c9_c11,  \n",
    "          c10_c11]\n",
    "\n",
    "avg = round(mean(sample),3)\n",
    "sd = round(statistics.stdev(sample),3)\n",
    " \n",
    "# Prints average & standard deviation\n",
    "print(\"Average:\", avg)\n",
    "print(\"Standard Deviation:\", sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Fleiss' kappa for Died\n",
    "\n",
    "all_died = true_died.copy(deep=True)\n",
    "all_died['count_A']  = all_died.eq('0').sum(axis=1)\n",
    "all_died['count_B']  = all_died.eq('1').sum(axis=1)\n",
    "all_died['count_C']  = all_died.eq('2').sum(axis=1)\n",
    "all_died['count_D']  = all_died.eq('3').sum(axis=1)\n",
    "all_died['count_E']  = all_died.eq('4').sum(axis=1)\n",
    "\n",
    "##drop unncessary cols\n",
    "cols = [ 'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11']\n",
    "\n",
    "all_died = all_died.drop(cols, axis = 1)\n",
    "\n",
    "all_died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Fleiss' kappa - Discharged Died\n",
    "\n",
    "fleiss_k = round(fleiss_kappa(all_died, method='fleiss'),3)\n",
    "\n",
    "print(\"Fleiss' kappa: {:.3f}\".format(fleiss_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 HiRID Predicted Label Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values of each group\n",
    "A_bar = [c1_A_pred, c2_A_pred, c3_A_pred, c4_A_pred, c5_A_pred, c6_A_pred, c7_A_pred, c8_A_pred, c9_A_pred, c10_A_pred, c11_A_pred]\n",
    "B_bar = [c1_B_pred, c2_B_pred, c3_B_pred, c4_B_pred, c5_B_pred, c6_B_pred, c7_B_pred, c8_B_pred, c9_B_pred, c10_B_pred, c11_B_pred]\n",
    "C_bar = [c1_C_pred, c2_C_pred, c3_C_pred, c4_C_pred, c5_C_pred, c6_C_pred, c7_C_pred, c8_C_pred, c9_C_pred, c10_C_pred, c11_C_pred]\n",
    "D_bar = [c1_D_pred, c2_D_pred, c3_D_pred, c4_D_pred, c5_D_pred, c6_D_pred, c7_D_pred, c8_D_pred, c9_D_pred, c10_D_pred, c11_D_pred]\n",
    "E_bar = [c1_E_pred, c2_E_pred, c3_E_pred, c4_E_pred, c5_E_pred, c6_E_pred, c7_E_pred, c8_E_pred, c9_E_pred, c10_E_pred, c11_E_pred]\n",
    "\n",
    "print(A_bar)\n",
    "print(B_bar)\n",
    "print(C_bar)\n",
    "print(D_bar)\n",
    "print(E_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked bar chart - predicted label distributions\n",
    "\n",
    "#Values of each group\n",
    "A_bar = [c1_A_pred, c2_A_pred, c3_A_pred, c4_A_pred, c5_A_pred, c6_A_pred, c7_A_pred, c8_A_pred, c9_A_pred, c10_A_pred, c11_A_pred]\n",
    "B_bar = [c1_B_pred, c2_B_pred, c3_B_pred, c4_B_pred, c5_B_pred, c6_B_pred, c7_B_pred, c8_B_pred, c9_B_pred, c10_B_pred, c11_B_pred]\n",
    "C_bar = [c1_C_pred, c2_C_pred, c3_C_pred, c4_C_pred, c5_C_pred, c6_C_pred, c7_C_pred, c8_C_pred, c9_C_pred, c10_C_pred, c11_C_pred]\n",
    "D_bar = [c1_D_pred, c2_D_pred, c3_D_pred, c4_D_pred, c5_D_pred, c6_D_pred, c7_D_pred, c8_D_pred, c9_D_pred, c10_D_pred, c11_D_pred]\n",
    "E_bar = [c1_E_pred, c2_E_pred, c3_E_pred, c4_E_pred, c5_E_pred, c6_E_pred, c7_E_pred, c8_E_pred, c9_E_pred, c10_E_pred, c11_E_pred]\n",
    "\n",
    "#Heights of A_bar + B_bar + C_bar + D_bar\n",
    "list_AB = np.array([A_bar,B_bar])\n",
    "AB_bars = np.sum(list_AB, axis=0)\n",
    "\n",
    "list_ABC = np.array([A_bar,B_bar,C_bar])\n",
    "ABC_bars = np.sum(list_ABC, axis=0)\n",
    "\n",
    "list_ABCD = np.array([A_bar,B_bar,C_bar,D_bar])\n",
    "ABCD_bars = np.sum(list_ABCD, axis=0)\n",
    "\n",
    "#Position of the bars on the x-axis\n",
    "r = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "#X-axis labels\n",
    "names = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    " \n",
    "#Plot bars\n",
    "barwidth = 1\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(r, A_bar, color='#4e79a7', edgecolor='white', width=barwidth, label = 'A')\n",
    "plt.bar(r, B_bar, bottom=A_bar, color='#59a14f', edgecolor='white', width=barwidth, label = 'B')\n",
    "plt.bar(r, C_bar, bottom=AB_bars, color='#ddaa33', edgecolor='white', width=barwidth, label = 'C')\n",
    "plt.bar(r, D_bar, bottom=ABC_bars, color='#b07aa1', edgecolor='white', width=barwidth, label = 'D')\n",
    "plt.bar(r, E_bar, bottom=ABCD_bars, color='#d6604d', edgecolor='white', width=barwidth, label = 'E')\n",
    "\n",
    "#Title and axis labels\n",
    "plt.xlabel(\"Annotator\", fontsize=16, labelpad=10)\n",
    "plt.xticks(r, names, fontsize=16)\n",
    "plt.ylabel(\"Predicted Label Distribution\", fontsize=16, labelpad=10)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim((0,2700))\n",
    "\n",
    "#Show legend\n",
    "plt.legend(loc=(1.02,0),fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "#Save plot\n",
    "plt.savefig('Multi-RF-Exp1-PredLabels.eps', format='eps')\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Pairwise Cohen's kappa - HiRID Predicted Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_pred = list(c1rf_multi_opt.predict(X_test))\n",
    "c2_pred = list(c2rf_multi_opt.predict(X_test))\n",
    "c3_pred = list(c3rf_multi_opt.predict(X_test))\n",
    "c4_pred = list(c4rf_multi_opt.predict(X_test))\n",
    "c5_pred = list(c5rf_multi_opt.predict(X_test))\n",
    "c6_pred = list(c6rf_multi_opt.predict(X_test))\n",
    "c7_pred = list(c7rf_multi_opt.predict(X_test))\n",
    "c8_pred = list(c8rf_multi_opt.predict(X_test))\n",
    "c9_pred = list(c9rf_multi_opt.predict(X_test))\n",
    "c10_pred = list(c10rf_multi_opt.predict(X_test))\n",
    "c11_pred = list(c11rf_multi_opt.predict(X_test))\n",
    "\n",
    "\n",
    "c1_pred = pd.DataFrame(data=c1_pred)\n",
    "c2_pred = pd.DataFrame(data=c2_pred)\n",
    "c3_pred = pd.DataFrame(data=c3_pred)\n",
    "c4_pred = pd.DataFrame(data=c4_pred)\n",
    "c5_pred = pd.DataFrame(data=c5_pred)\n",
    "c6_pred = pd.DataFrame(data=c6_pred)\n",
    "c7_pred = pd.DataFrame(data=c7_pred)\n",
    "c8_pred = pd.DataFrame(data=c8_pred)\n",
    "c9_pred = pd.DataFrame(data=c9_pred)\n",
    "c10_pred = pd.DataFrame(data=c10_pred)\n",
    "c11_pred = pd.DataFrame(data=c11_pred)\n",
    "\n",
    "\n",
    "c1_pred.columns = [\"C1\"]\n",
    "c2_pred.columns = [\"C2\"]\n",
    "c3_pred.columns = [\"C3\"]\n",
    "c4_pred.columns = [\"C4\"]\n",
    "c5_pred.columns = [\"C5\"]\n",
    "c6_pred.columns = [\"C6\"]\n",
    "c7_pred.columns = [\"C7\"]\n",
    "c8_pred.columns = [\"C8\"]\n",
    "c9_pred.columns = [\"C9\"]\n",
    "c10_pred.columns = [\"C10\"]\n",
    "c11_pred.columns = [\"C11\"]\n",
    "\n",
    "frames = [c1_pred, c2_pred, c3_pred, c4_pred, c5_pred, c6_pred, c7_pred, c8_pred, c9_pred, c10_pred, c11_pred]\n",
    "\n",
    "ann_pred = pd.concat(frames, axis=1)\n",
    "\n",
    "print(ann_pred.shape)\n",
    "ann_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare C2, C4, C8 HiRID predicted labels\n",
    "\n",
    "#C2\n",
    "c2_labs = {'HiRID Predicted Label': ['A', 'B', 'C', 'D', 'E'], 'C2': [c2_A_pred, c2_B_pred, c2_C_pred, c2_D_pred, c2_E_pred]}\n",
    "c2_pred_labs = pd.DataFrame(data=c2_labs)\n",
    "c2_pred_labs['C2 %'] = ((c2_pred_labs['C2']/2600)*100)\n",
    "\n",
    "#C4\n",
    "c4_labs = {'HiRID Predicted Label': ['A', 'B', 'C', 'D', 'E'], 'C4': [c4_A_pred, c4_B_pred, c4_C_pred, c4_D_pred, c4_E_pred]}\n",
    "c4_pred_labs = pd.DataFrame(data=c4_labs)\n",
    "c4_pred_labs['C4 %'] = ((c4_pred_labs['C4']/2600)*100)\n",
    "\n",
    "#C8\n",
    "c8_labs = {'HiRID Predicted Label': ['A', 'B', 'C', 'D', 'E'], 'C8': [c4_A_pred, c4_B_pred, c4_C_pred, c4_D_pred, c4_E_pred]}\n",
    "c8_pred_labs = pd.DataFrame(data=c8_labs)\n",
    "c8_pred_labs['C8 %'] = ((c8_pred_labs['C8']/2600)*100)\n",
    "\n",
    "\n",
    "#MERGE\n",
    "pred_dist = c2_pred_labs.merge(c4_pred_labs, on='HiRID Predicted Label').merge(c8_pred_labs, on='HiRID Predicted Label')\n",
    "pred_dist = pred_dist.sort_values(by='HiRID Predicted Label', ascending=True)\n",
    "pred_dist = pred_dist.drop(['C2','C4','C8'], axis=1)\n",
    "\n",
    "pred_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate pairwise Cohen's kappa\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score \n",
    "\n",
    "c1_pred = ann_pred.iloc[:,0]\n",
    "c2_pred = ann_pred.iloc[:,1]\n",
    "c3_pred = ann_pred.iloc[:,2]\n",
    "c4_pred = ann_pred.iloc[:,3]\n",
    "c5_pred = ann_pred.iloc[:,4]\n",
    "c6_pred = ann_pred.iloc[:,5]\n",
    "c7_pred = ann_pred.iloc[:,6]\n",
    "c8_pred = ann_pred.iloc[:,7]\n",
    "c9_pred = ann_pred.iloc[:,8]\n",
    "c10_pred = ann_pred.iloc[:,9]\n",
    "c11_pred = ann_pred.iloc[:,10]\n",
    "\n",
    "c1_c2 = round(cohen_kappa_score(c1_pred, c2_pred),2)\n",
    "c1_c3 = round(cohen_kappa_score(c1_pred, c3_pred),2)\n",
    "c1_c4 = round(cohen_kappa_score(c1_pred, c4_pred),2)\n",
    "c1_c5 = round(cohen_kappa_score(c1_pred, c5_pred),2)\n",
    "c1_c6 = round(cohen_kappa_score(c1_pred, c6_pred),2)\n",
    "c1_c7 = round(cohen_kappa_score(c1_pred, c7_pred),2)\n",
    "c1_c8 = round(cohen_kappa_score(c1_pred, c8_pred),2)\n",
    "c1_c9 = round(cohen_kappa_score(c1_pred, c9_pred),2)\n",
    "c1_c10 = round(cohen_kappa_score(c1_pred, c10_pred),2)\n",
    "c1_c11 = round(cohen_kappa_score(c1_pred, c11_pred),2)\n",
    "\n",
    "c2_c3 = round(cohen_kappa_score(c2_pred, c3_pred),2)\n",
    "c2_c4 = round(cohen_kappa_score(c2_pred, c4_pred),2)\n",
    "c2_c5 = round(cohen_kappa_score(c2_pred, c5_pred),2)\n",
    "c2_c6 = round(cohen_kappa_score(c2_pred, c6_pred),2)\n",
    "c2_c7 = round(cohen_kappa_score(c2_pred, c7_pred),2)\n",
    "c2_c8 = round(cohen_kappa_score(c2_pred, c8_pred),2)\n",
    "c2_c9 = round(cohen_kappa_score(c2_pred, c9_pred),2)\n",
    "c2_c10 = round(cohen_kappa_score(c2_pred, c10_pred),2)\n",
    "c2_c11 = round(cohen_kappa_score(c2_pred, c11_pred),2)\n",
    "\n",
    "c3_c4 = round(cohen_kappa_score(c3_pred, c4_pred),2)\n",
    "c3_c5 = round(cohen_kappa_score(c3_pred, c5_pred),2)\n",
    "c3_c6 = round(cohen_kappa_score(c3_pred, c6_pred),2)\n",
    "c3_c7 = round(cohen_kappa_score(c3_pred, c7_pred),2)\n",
    "c3_c8 = round(cohen_kappa_score(c3_pred, c8_pred),2)\n",
    "c3_c9 = round(cohen_kappa_score(c3_pred, c9_pred),2)\n",
    "c3_c10 = round(cohen_kappa_score(c3_pred, c10_pred),2)\n",
    "c3_c11 = round(cohen_kappa_score(c3_pred, c11_pred),2)\n",
    "\n",
    "c4_c5 = round(cohen_kappa_score(c4_pred, c5_pred),2)\n",
    "c4_c6 = round(cohen_kappa_score(c4_pred, c6_pred),2)\n",
    "c4_c7 = round(cohen_kappa_score(c4_pred, c7_pred),2)\n",
    "c4_c8 = round(cohen_kappa_score(c4_pred, c8_pred),2)\n",
    "c4_c9 = round(cohen_kappa_score(c4_pred, c9_pred),2)\n",
    "c4_c10 = round(cohen_kappa_score(c4_pred, c10_pred),2)\n",
    "c4_c11 = round(cohen_kappa_score(c4_pred, c11_pred),2)\n",
    "\n",
    "c5_c6 = round(cohen_kappa_score(c5_pred, c6_pred),2)\n",
    "c5_c7 = round(cohen_kappa_score(c5_pred, c7_pred),2)\n",
    "c5_c8 = round(cohen_kappa_score(c5_pred, c8_pred),2)\n",
    "c5_c9 = round(cohen_kappa_score(c5_pred, c9_pred),2)\n",
    "c5_c10 = round(cohen_kappa_score(c5_pred, c10_pred),2)\n",
    "c5_c11 = round(cohen_kappa_score(c5_pred, c11_pred),2)\n",
    "\n",
    "c6_c7 = round(cohen_kappa_score(c6_pred, c7_pred),2)\n",
    "c6_c8 = round(cohen_kappa_score(c6_pred, c8_pred),2)\n",
    "c6_c9 = round(cohen_kappa_score(c6_pred, c9_pred),2)\n",
    "c6_c10 = round(cohen_kappa_score(c6_pred, c10_pred),2)\n",
    "c6_c11 = round(cohen_kappa_score(c6_pred, c11_pred),2)\n",
    "\n",
    "c7_c8 = round(cohen_kappa_score(c7_pred, c8_pred),2)\n",
    "c7_c9 = round(cohen_kappa_score(c7_pred, c9_pred),2)\n",
    "c7_c10 = round(cohen_kappa_score(c7_pred, c10_pred),2)\n",
    "c7_c11 = round(cohen_kappa_score(c7_pred, c11_pred),2)\n",
    "\n",
    "c8_c9 = round(cohen_kappa_score(c8_pred, c9_pred),2)\n",
    "c8_c10 = round(cohen_kappa_score(c8_pred, c10_pred),2)\n",
    "c8_c11 = round(cohen_kappa_score(c8_pred, c11_pred),2)\n",
    "\n",
    "c9_c10 = round(cohen_kappa_score(c9_pred, c10_pred),2)\n",
    "c9_c11 = round(cohen_kappa_score(c9_pred, c11_pred),2)\n",
    "\n",
    "c10_c11 = round(cohen_kappa_score(c10_pred, c11_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "C1 = [1.00, c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11]\n",
    "C2 = [\"\", 1.00, c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11]\n",
    "C3 = [\"\", \"\", 1.00, c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11]\n",
    "C4 = [\"\", \"\", \"\", 1.00, c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11]\n",
    "C5 = [\"\", \"\", \"\", \"\", 1.00, c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11]\n",
    "C6 = [\"\", \"\", \"\", \"\", \"\", 1.00, c6_c7, c6_c8, c6_c9, c6_c10, c6_c11]\n",
    "C7 = [\"\", \"\", \"\", \"\", \"\", \"\", 1.00, c7_c8, c7_c9, c7_c10, c7_c11]\n",
    "C8 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c8_c9, c8_c10, c8_c11]\n",
    "C9 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c9_c10, c9_c11]\n",
    "C10 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1.00, c10_c11]\n",
    "C11 = [\"\", \"\", \"\", \"\", \"\", \"\" , \"\", \"\", \"\", \"\", 1.00]\n",
    "\n",
    "C0 = pd.DataFrame(data=C0)\n",
    "C1 = pd.DataFrame(data=C1)\n",
    "C2 = pd.DataFrame(data=C2)\n",
    "C3 = pd.DataFrame(data=C3)\n",
    "C4 = pd.DataFrame(data=C4)\n",
    "C5 = pd.DataFrame(data=C5)\n",
    "C6 = pd.DataFrame(data=C6)\n",
    "C7 = pd.DataFrame(data=C7)\n",
    "C8 = pd.DataFrame(data=C8)\n",
    "C9 = pd.DataFrame(data=C9)\n",
    "C10 = pd.DataFrame(data=C10)\n",
    "C11 = pd.DataFrame(data=C11)\n",
    "\n",
    "C0.columns = [\"\"]\n",
    "C1.columns = ['C1']\n",
    "C2.columns = ['C2']\n",
    "C3.columns = ['C3']\n",
    "C4.columns = ['C4']\n",
    "C5.columns = ['C5']\n",
    "C6.columns = ['C6']\n",
    "C7.columns = ['C7']\n",
    "C8.columns = ['C8']\n",
    "C9.columns = ['C9']\n",
    "C10.columns = ['C10']\n",
    "C11.columns = ['C11']\n",
    "\n",
    "\n",
    "frames = [C0,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11]\n",
    "\n",
    "cohen_k = pd.concat(frames, axis=1)\n",
    "cohen_k = cohen_k.set_index(\"\")\n",
    "\n",
    "cohen_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\"]\n",
    "cohen_k[cols] = cohen_k[cols].apply(pd.to_numeric)\n",
    "\n",
    "cohen_k.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot pairwise Cohen's kappa\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(6, 4), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "res = sns.heatmap(cohen_k, annot=True, vmin=0, vmax=1, cbar=False,\n",
    "                  fmt='.2f', cmap=\"YlGnBu\", annot_kws={\"fontsize\":12})\n",
    "\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 12)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Multi-RF-Exp1-Pairwise-CohenK.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average & SD of pairwise cohen's kappa values (all labels)\n",
    "\n",
    "pred_iaa = [c1_c2, c1_c3, c1_c4, c1_c5, c1_c6, c1_c7, c1_c8, c1_c9, c1_c10, c1_c11,\n",
    "          c2_c3, c2_c4, c2_c5, c2_c6, c2_c7, c2_c8, c2_c9, c2_c10, c2_c11, \n",
    "          c3_c4, c3_c5, c3_c6, c3_c7, c3_c8, c3_c9, c3_c10, c3_c11, \n",
    "          c4_c5, c4_c6, c4_c7, c4_c8, c4_c9, c4_c10, c4_c11, \n",
    "          c5_c6, c5_c7, c5_c8, c5_c9, c5_c10, c5_c11, \n",
    "          c6_c7, c6_c8, c6_c9, c6_c10, c6_c11, \n",
    "          c7_c8, c7_c9, c7_c10, c7_c11, \n",
    "          c8_c9, c8_c10, c8_c11, \n",
    "          c9_c10, c9_c11,\n",
    "          c10_c11]\n",
    "\n",
    "avg = round(mean(pred_iaa),3)\n",
    "sd = round(statistics.stdev(pred_iaa),3)\n",
    " \n",
    "# Prints average & standard deviation\n",
    "print(\"Average:\", avg)\n",
    "print(\"Standard Deviation:\", sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fleiss' kappa (All Predicted labels) - part 1\n",
    "\n",
    "all_ann = ann_pred.copy(deep=True)\n",
    "all_ann = all_ann.applymap(str)\n",
    "all_ann['count_A']  = all_ann.eq('0').sum(axis=1)\n",
    "all_ann['count_B']  = all_ann.eq('1').sum(axis=1)\n",
    "all_ann['count_C']  = all_ann.eq('2').sum(axis=1)\n",
    "all_ann['count_D']  = all_ann.eq('3').sum(axis=1)\n",
    "all_ann['count_E']  = all_ann.eq('4').sum(axis=1)\n",
    "\n",
    "##drop unncessary cols\n",
    "cols = [ 'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11']\n",
    "\n",
    "all_ann = all_ann.drop(cols, axis = 1)\n",
    "\n",
    "all_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fleiss' kappa (All Predicted labels) - part 2\n",
    "\n",
    "fleiss_k = round(fleiss_kappa(all_ann, method='fleiss'),3)\n",
    "\n",
    "print(\"Fleiss' kappa: {:.3f}\".format(fleiss_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
